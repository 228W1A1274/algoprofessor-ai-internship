{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Day 12 — Cache Benchmark\n",
    "**Internship Task:** Compare caching patterns: Cache-Aside, Write-Through, Write-Behind  \n",
    "**Tools:** `redis-py`, `pymongo`, `time`, `matplotlib`\n",
    "\n",
    "> Ensure MongoDB and Redis are running before executing cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import redis\n",
    "import time\n",
    "import json\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Connections\n",
    "r = redis.Redis(host='localhost', port=6379, db=1, decode_responses=True)\n",
    "client = MongoClient('mongodb://localhost:27017')\n",
    "db = client['benchmark_db']\n",
    "col = db['products']\n",
    "\n",
    "# Seed MongoDB with 100 products\n",
    "col.drop()\n",
    "products = [{'_id': i, 'name': f'Product_{i}', 'price': round(random.uniform(10, 5000), 2), 'stock': random.randint(0, 500)} for i in range(1, 101)]\n",
    "col.insert_many(products)\n",
    "print(f'✅ Seeded {col.count_documents({})} products into MongoDB')\n",
    "print(f'✅ Redis connected: {r.ping()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 1 — Cache-Aside (Lazy Loading)\n",
    "**How it works:**\n",
    "1. App checks cache first\n",
    "2. If **MISS** → fetch from DB → store in cache → return\n",
    "3. If **HIT** → return from cache directly\n",
    "\n",
    "**Best for:** Read-heavy workloads where not all data is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CACHE_TTL = 60   # seconds\n",
    "\n",
    "def cache_aside_get(product_id: int) -> dict:\n",
    "    key = f'cache_aside:product:{product_id}'\n",
    "    cached = r.get(key)\n",
    "    if cached:\n",
    "        return json.loads(cached), 'HIT'\n",
    "    # Cache MISS — go to DB\n",
    "    doc = col.find_one({'_id': product_id}, {'_id': 0})\n",
    "    r.setex(key, CACHE_TTL, json.dumps(doc))\n",
    "    return doc, 'MISS'\n",
    "\n",
    "# Clear cache for clean test\n",
    "for k in r.keys('cache_aside:*'): r.delete(k)\n",
    "\n",
    "# Benchmark: 200 reads (IDs 1-20 repeated to create hits)\n",
    "ids = [random.randint(1, 20) for _ in range(200)]\n",
    "times_ca, hits_ca, misses_ca = [], 0, 0\n",
    "\n",
    "for pid in ids:\n",
    "    t0 = time.perf_counter()\n",
    "    _, status = cache_aside_get(pid)\n",
    "    times_ca.append((time.perf_counter() - t0) * 1000)  # ms\n",
    "    if status == 'HIT': hits_ca += 1\n",
    "    else: misses_ca += 1\n",
    "\n",
    "hit_rate_ca = hits_ca / len(ids) * 100\n",
    "avg_ca = sum(times_ca) / len(times_ca)\n",
    "print(f'Cache-Aside: hits={hits_ca}, misses={misses_ca}, hit_rate={hit_rate_ca:.1f}%')\n",
    "print(f'Avg response time = {avg_ca:.3f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 2 — Write-Through\n",
    "**How it works:**\n",
    "- Every **write** updates **both** cache AND database synchronously\n",
    "- Cache is always in sync with DB\n",
    "\n",
    "**Best for:** Read-heavy workloads where data consistency is critical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_through_update(product_id: int, new_price: float):\n",
    "    key = f'write_through:product:{product_id}'\n",
    "    # Update DB first\n",
    "    col.update_one({'_id': product_id}, {'$set': {'price': new_price}})\n",
    "    # Immediately update cache\n",
    "    doc = col.find_one({'_id': product_id}, {'_id': 0})\n",
    "    r.setex(key, CACHE_TTL, json.dumps(doc))\n",
    "    return doc\n",
    "\n",
    "def write_through_get(product_id: int):\n",
    "    key = f'write_through:product:{product_id}'\n",
    "    cached = r.get(key)\n",
    "    if cached: return json.loads(cached), 'HIT'\n",
    "    doc = col.find_one({'_id': product_id}, {'_id': 0})\n",
    "    r.setex(key, CACHE_TTL, json.dumps(doc))\n",
    "    return doc, 'MISS'\n",
    "\n",
    "for k in r.keys('write_through:*'): r.delete(k)\n",
    "\n",
    "# Benchmark: 100 writes + 100 reads\n",
    "write_times_wt, read_times_wt = [], []\n",
    "\n",
    "for i in range(1, 101):\n",
    "    t0 = time.perf_counter()\n",
    "    write_through_update(i, round(random.uniform(10, 5000), 2))\n",
    "    write_times_wt.append((time.perf_counter() - t0) * 1000)\n",
    "\n",
    "for pid in [random.randint(1, 100) for _ in range(100)]:\n",
    "    t0 = time.perf_counter()\n",
    "    write_through_get(pid)\n",
    "    read_times_wt.append((time.perf_counter() - t0) * 1000)\n",
    "\n",
    "avg_write_wt = sum(write_times_wt) / len(write_times_wt)\n",
    "avg_read_wt  = sum(read_times_wt)  / len(read_times_wt)\n",
    "print(f'Write-Through: avg write = {avg_write_wt:.3f} ms | avg read = {avg_read_wt:.3f} ms')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pattern 3 — Write-Behind (Write-Back)\n",
    "**How it works:**\n",
    "- Write goes to **cache immediately** (fast response)\n",
    "- DB write happens **later** in batch (async)\n",
    "\n",
    "**Best for:** Write-heavy workloads where you can tolerate a short data-loss window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIRTY_SET = 'write_behind:dirty_keys'\n",
    "\n",
    "def write_behind_update(product_id: int, new_price: float):\n",
    "    key = f'write_behind:product:{product_id}'\n",
    "    doc = {'price': new_price, 'product_id': product_id}\n",
    "    r.setex(key, CACHE_TTL, json.dumps(doc))\n",
    "    r.sadd(DIRTY_SET, product_id)   # mark as needing DB sync\n",
    "    return doc\n",
    "\n",
    "def flush_dirty_to_db():\n",
    "    \"\"\"Called periodically to sync cache → DB.\"\"\"\n",
    "    dirty_ids = r.smembers(DIRTY_SET)\n",
    "    flushed = 0\n",
    "    for pid in dirty_ids:\n",
    "        key = f'write_behind:product:{int(pid)}'\n",
    "        cached = r.get(key)\n",
    "        if cached:\n",
    "            data = json.loads(cached)\n",
    "            col.update_one({'_id': int(pid)}, {'$set': {'price': data['price']}})\n",
    "            r.srem(DIRTY_SET, pid)\n",
    "            flushed += 1\n",
    "    return flushed\n",
    "\n",
    "for k in r.keys('write_behind:*'): r.delete(k)\n",
    "\n",
    "write_times_wb = []\n",
    "for i in range(1, 101):\n",
    "    t0 = time.perf_counter()\n",
    "    write_behind_update(i, round(random.uniform(10, 5000), 2))\n",
    "    write_times_wb.append((time.perf_counter() - t0) * 1000)\n",
    "\n",
    "avg_write_wb = sum(write_times_wb) / len(write_times_wb)\n",
    "print(f'Write-Behind: avg write = {avg_write_wb:.3f} ms (cache only, no DB yet)')\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "flushed = flush_dirty_to_db()\n",
    "flush_time = (time.perf_counter() - t0) * 1000\n",
    "print(f'Flush {flushed} records to DB = {flush_time:.1f} ms total ({flush_time/flushed:.2f} ms each)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TTL & Eviction Policy Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('── TTL Demonstration ───────────────────────')\n",
    "r.set('demo:ttl_short', 'expires in 3s', ex=3)\n",
    "r.set('demo:ttl_long',  'expires in 60s', ex=60)\n",
    "r.set('demo:no_ttl',    'never expires')\n",
    "\n",
    "print(f\"TTL short  : {r.ttl('demo:ttl_short')} sec\")\n",
    "print(f\"TTL long   : {r.ttl('demo:ttl_long')} sec\")\n",
    "print(f\"TTL no_ttl : {r.ttl('demo:no_ttl')} (-1 = no expiry)\")\n",
    "\n",
    "time.sleep(3.5)\n",
    "print(f\"\\nAfter 3.5 sec wait:\")\n",
    "print(f\"  short_lived exists? {r.exists('demo:ttl_short') == 1}\")\n",
    "print(f\"  long key exists?    {r.exists('demo:ttl_long') == 1}\")\n",
    "\n",
    "print('\\n── Eviction Policy ─────────────────────────')\n",
    "policy = r.config_get('maxmemory-policy')\n",
    "print(f\"Current: {policy}\")\n",
    "print(\"\\nPolicy options:\")\n",
    "policies = [\n",
    "    ('noeviction',      'Returns error when memory is full (default)'),\n",
    "    ('allkeys-lru',     'Evict least recently used keys'),\n",
    "    ('volatile-lru',    'Evict LRU keys with TTL only'),\n",
    "    ('allkeys-lfu',     'Evict least frequently used keys'),\n",
    "    ('volatile-ttl',    'Evict keys with shortest TTL first'),\n",
    "    ('allkeys-random',  'Evict random keys'),\n",
    "]\n",
    "for name, desc in policies:\n",
    "    print(f\"  {name:20s} → {desc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benchmark Comparison Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "fig.suptitle('Day 12 — Caching Pattern Benchmark', fontsize=15, fontweight='bold')\n",
    "\n",
    "# ── Plot 1: Response time distribution ──────\n",
    "miss_times = [t for t, (_, s) in zip(times_ca, [cache_aside_get(pid) for pid in ids[:50]]) if s == 'MISS']\n",
    "# Approximate: first 20 are misses, rest are hits\n",
    "hit_times_ca  = times_ca[20:]\n",
    "miss_times_ca = times_ca[:20]\n",
    "\n",
    "axes[0].boxplot([miss_times_ca, hit_times_ca], labels=['Cache MISS\\n(DB query)', 'Cache HIT\\n(Redis only)'])\n",
    "axes[0].set_title('Cache-Aside\\nHit vs Miss Latency')\n",
    "axes[0].set_ylabel('Response Time (ms)')\n",
    "axes[0].set_facecolor('#f8f9fa')\n",
    "\n",
    "# ── Plot 2: Write latency comparison ─────────\n",
    "patterns = ['Write-Through\\n(DB+Cache)', 'Write-Behind\\n(Cache only)']\n",
    "avgs     = [avg_write_wt, avg_write_wb]\n",
    "colors   = ['#e74c3c', '#2ecc71']\n",
    "bars = axes[1].bar(patterns, avgs, color=colors, edgecolor='white', linewidth=1.5, width=0.5)\n",
    "for bar, val in zip(bars, avgs):\n",
    "    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                 f'{val:.3f}ms', ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "axes[1].set_title('Write Latency Comparison')\n",
    "axes[1].set_ylabel('Avg Write Time (ms)')\n",
    "axes[1].set_facecolor('#f8f9fa')\n",
    "\n",
    "# ── Plot 3: Cache-Aside hit rate pie ─────────\n",
    "axes[2].pie(\n",
    "    [hits_ca, misses_ca],\n",
    "    labels=[f'HIT ({hits_ca})', f'MISS ({misses_ca})'],\n",
    "    colors=['#2ecc71', '#e74c3c'],\n",
    "    autopct='%1.1f%%',\n",
    "    startangle=90,\n",
    "    explode=(0.05, 0)\n",
    ")\n",
    "axes[2].set_title(f'Cache-Aside Hit Rate\\n{hit_rate_ca:.1f}% over 200 reads')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('cache_benchmark_results.png', dpi=150, bbox_inches='tight')\n",
    "plt.show()\n",
    "print('Chart saved: cache_benchmark_results.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=' * 70)\n",
    "print(f'{\"CACHING PATTERN BENCHMARK SUMMARY\":^70}')\n",
    "print('=' * 70)\n",
    "\n",
    "print(f'\\n{\"Pattern\":<20} {\"Avg Latency\":<18} {\"Consistency\":<20} {\"Best For\"}')\n",
    "print('-' * 70)\n",
    "rows = [\n",
    "    ('Cache-Aside',    f'{avg_ca:.3f} ms (read)',   'Eventual',   'Read-heavy, sparse access'),\n",
    "    ('Write-Through',  f'{avg_write_wt:.3f} ms (write)', 'Strong', 'Read-heavy, always fresh'),\n",
    "    ('Write-Behind',   f'{avg_write_wb:.3f} ms (write)', 'Eventual', 'Write-heavy, tolerate lag'),\n",
    "]\n",
    "for r_name, lat, cons, best in rows:\n",
    "    print(f'{r_name:<20} {lat:<18} {cons:<20} {best}')\n",
    "\n",
    "print('=' * 70)\n",
    "print(f'\\nCache-Aside Hit Rate : {hit_rate_ca:.1f}%')\n",
    "print(f'Write-Behind speedup : {avg_write_wt / avg_write_wb:.1f}x faster than Write-Through')\n",
    "print('\\n✅ cache_benchmark.ipynb completed!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
