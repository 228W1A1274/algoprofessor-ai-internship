{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Myq2z0dngLc6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "os.makedirs(\"training_logs\", exist_ok=True)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirements.txt\n",
        "numpy\n",
        "pandas\n",
        "matplotlib\n",
        "tensorflow\n",
        "scikit-learn\n",
        "seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MU0cyyJ7i1nD",
        "outputId": "d1e0d470-bea9-4432-8b09-cb9839db7f9c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing requirements.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile neural_network_scratch.py\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_digits\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "\n",
        "class SimpleNN:\n",
        "    def __init__(self, input_size, hidden_size, output_size):\n",
        "        # He Initialization (Crucial for high accuracy)\n",
        "        self.W1 = np.random.randn(input_size, hidden_size) * np.sqrt(2/input_size)\n",
        "        self.b1 = np.zeros((1, hidden_size))\n",
        "        self.W2 = np.random.randn(hidden_size, output_size) * np.sqrt(2/hidden_size)\n",
        "        self.b2 = np.zeros((1, output_size))\n",
        "\n",
        "    def relu(self, Z):\n",
        "        return np.maximum(0, Z)\n",
        "\n",
        "    def softmax(self, Z):\n",
        "        expZ = np.exp(Z - np.max(Z, axis=1, keepdims=True))\n",
        "        return expZ / np.sum(expZ, axis=1, keepdims=True)\n",
        "\n",
        "    def forward(self, X):\n",
        "        self.Z1 = np.dot(X, self.W1) + self.b1\n",
        "        self.A1 = self.relu(self.Z1)\n",
        "        self.Z2 = np.dot(self.A1, self.W2) + self.b2\n",
        "        self.A2 = self.softmax(self.Z2)\n",
        "        return self.A2\n",
        "\n",
        "    def backward(self, X, y_true, learning_rate=0.1):\n",
        "        m = y_true.shape[0]\n",
        "        dZ2 = self.A2 - y_true\n",
        "        dW2 = (1/m) * np.dot(self.A1.T, dZ2)\n",
        "        db2 = (1/m) * np.sum(dZ2, axis=0, keepdims=True)\n",
        "        dA1 = np.dot(dZ2, self.W2.T)\n",
        "        dZ1 = dA1 * (self.Z1 > 0)\n",
        "        dW1 = (1/m) * np.dot(X.T, dZ1)\n",
        "        db1 = (1/m) * np.sum(dZ1, axis=0, keepdims=True)\n",
        "        self.W1 -= learning_rate * dW1\n",
        "        self.b1 -= learning_rate * db1\n",
        "        self.W2 -= learning_rate * dW2\n",
        "        self.b2 -= learning_rate * db2\n",
        "\n",
        "    def train(self, X, y, epochs=1000, lr=0.1):\n",
        "        print(f\"--- Training NN from Scratch on Digits Data ---\")\n",
        "        final_acc = 0\n",
        "        for i in range(epochs):\n",
        "            y_pred = self.forward(X)\n",
        "            self.backward(X, y, learning_rate=lr)\n",
        "\n",
        "            if i % 100 == 0:\n",
        "                predictions = np.argmax(y_pred, axis=1)\n",
        "                true_labels = np.argmax(y, axis=1)\n",
        "                final_acc = np.mean(predictions == true_labels)\n",
        "                print(f\"Epoch {i}: Accuracy = {final_acc*100:.2f}%\")\n",
        "        return final_acc\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # 1. Load Real Data\n",
        "    digits = load_digits()\n",
        "    X = digits.data\n",
        "    y = digits.target.reshape(-1, 1)\n",
        "\n",
        "    # 2. Scale Data (StandardScaler is vital for convergence)\n",
        "    scaler = StandardScaler()\n",
        "    X = scaler.fit_transform(X)\n",
        "\n",
        "    encoder = OneHotEncoder(sparse_output=False)\n",
        "    y_onehot = encoder.fit_transform(y)\n",
        "\n",
        "    # 3. Train\n",
        "    nn = SimpleNN(input_size=64, hidden_size=64, output_size=10)\n",
        "    final_acc = nn.train(X, y_onehot, epochs=2000, lr=0.5)\n",
        "\n",
        "    # 4. Save Proof\n",
        "    with open(\"results_scratch.txt\", \"w\") as f:\n",
        "        f.write(f\"Manual NN Accuracy: {final_acc*100:.2f}%\")\n",
        "    print(f\"\\n[Success] Results saved to results_scratch.txt\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBwfR3A5jDFO",
        "outputId": "bd3823d7-793d-4d10-f50a-dd5512415ced"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting neural_network_scratch.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python neural_network_scratch.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrpxbTqTjaQI",
        "outputId": "84f6bd66-4236-499b-b8cb-8615901e36a4"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training NN from Scratch on Digits Data ---\n",
            "Epoch 0: Accuracy = 14.58%\n",
            "Epoch 100: Accuracy = 99.39%\n",
            "Epoch 200: Accuracy = 99.83%\n",
            "Epoch 300: Accuracy = 100.00%\n",
            "Epoch 400: Accuracy = 100.00%\n",
            "Epoch 500: Accuracy = 100.00%\n",
            "Epoch 600: Accuracy = 100.00%\n",
            "Epoch 700: Accuracy = 100.00%\n",
            "Epoch 800: Accuracy = 100.00%\n",
            "Epoch 900: Accuracy = 100.00%\n",
            "Epoch 1000: Accuracy = 100.00%\n",
            "Epoch 1100: Accuracy = 100.00%\n",
            "Epoch 1200: Accuracy = 100.00%\n",
            "Epoch 1300: Accuracy = 100.00%\n",
            "Epoch 1400: Accuracy = 100.00%\n",
            "Epoch 1500: Accuracy = 100.00%\n",
            "Epoch 1600: Accuracy = 100.00%\n",
            "Epoch 1700: Accuracy = 100.00%\n",
            "Epoch 1800: Accuracy = 100.00%\n",
            "Epoch 1900: Accuracy = 100.00%\n",
            "\n",
            "[Success] Results saved to results_scratch.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile cnn_classifier.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "def train_cnn():\n",
        "    print(\"--- Loading MNIST Data for CNN ---\")\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
        "\n",
        "    # Reshape and Scale\n",
        "    X_train = X_train.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "    X_test = X_test.reshape(-1, 28, 28, 1).astype(\"float32\") / 255.0\n",
        "\n",
        "    print(\"--- Building CNN Architecture ---\")\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    print(\"--- Training CNN ---\")\n",
        "    history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_split=0.1)\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Final Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # Save Model & Proof\n",
        "    model.save(\"models/cnn_mnist.keras\")\n",
        "\n",
        "    with open(\"results_cnn.txt\", \"w\") as f:\n",
        "        f.write(f\"CNN MNIST Accuracy: {test_acc*100:.2f}%\")\n",
        "    print(\"\\n[Success] Results saved to results_cnn.txt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_cnn()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARsqplVjkn66",
        "outputId": "37fe42f1-c4f1-462a-9aee-48df8734557f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing cnn_classifier.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python cnn_classifier.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGkn-KhlkpUi",
        "outputId": "7ce5f0f2-69a1-42ba-f829-7c5675825267"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-04 16:53:31.201925: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770224011.219964    5103 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770224011.225394    5103 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770224011.239237    5103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770224011.239265    5103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770224011.239268    5103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770224011.239271    5103 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-04 16:53:31.243542: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "--- Loading MNIST Data for CNN ---\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "--- Building CNN Architecture ---\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
            "2026-02-04 16:53:38.640304: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770224018.642188    5103 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "--- Training CNN ---\n",
            "Epoch 1/5\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "I0000 00:00:1770224021.311728    5154 service.cc:152] XLA service 0x78f11400db40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
            "I0000 00:00:1770224021.311774    5154 service.cc:160]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
            "2026-02-04 16:53:41.371836: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
            "I0000 00:00:1770224021.586651    5154 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "2026-02-04 16:53:42.319545: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[64,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,28,28]{3,2,1,0} %bitcast.1911, f32[32,1,3,3]{3,2,1,0} %bitcast.1918, f32[32]{0} %bitcast.2364), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2026-02-04 16:53:42.466794: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[64,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,32,13,13]{3,2,1,0} %bitcast.2428, f32[64,32,3,3]{3,2,1,0} %bitcast.1938, f32[64]{0} %bitcast.2488), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "I0000 00:00:1770224024.057212    5154 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
            "\u001b[1m827/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8633 - loss: 0.44362026-02-04 16:53:46.563047: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[48,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[48,1,28,28]{3,2,1,0} %bitcast.1911, f32[32,1,3,3]{3,2,1,0} %bitcast.1918, f32[32]{0} %bitcast.2364), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2026-02-04 16:53:46.574678: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[48,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[48,32,13,13]{3,2,1,0} %bitcast.2428, f32[64,32,3,3]{3,2,1,0} %bitcast.1938, f32[64]{0} %bitcast.2488), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kNone\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8649 - loss: 0.43842026-02-04 16:53:47.954982: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[64,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,1,28,28]{3,2,1,0} %bitcast.499, f32[32,1,3,3]{3,2,1,0} %bitcast.506, f32[32]{0} %bitcast.508), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2026-02-04 16:53:47.974379: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[64,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[64,32,13,13]{3,2,1,0} %bitcast.515, f32[64,32,3,3]{3,2,1,0} %bitcast.522, f32[64]{0} %bitcast.524), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2026-02-04 16:53:48.761011: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[48,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[48,1,28,28]{3,2,1,0} %bitcast.499, f32[32,1,3,3]{3,2,1,0} %bitcast.506, f32[32]{0} %bitcast.508), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2026-02-04 16:53:48.776530: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[48,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[48,32,13,13]{3,2,1,0} %bitcast.515, f32[64,32,3,3]{3,2,1,0} %bitcast.522, f32[64]{0} %bitcast.524), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 6ms/step - accuracy: 0.8650 - loss: 0.4381 - val_accuracy: 0.9782 - val_loss: 0.0766\n",
            "Epoch 2/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9819 - loss: 0.0573 - val_accuracy: 0.9873 - val_loss: 0.0473\n",
            "Epoch 3/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9873 - loss: 0.0419 - val_accuracy: 0.9877 - val_loss: 0.0432\n",
            "Epoch 4/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9904 - loss: 0.0315 - val_accuracy: 0.9913 - val_loss: 0.0321\n",
            "Epoch 5/5\n",
            "\u001b[1m844/844\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0206 - val_accuracy: 0.9880 - val_loss: 0.0457\n",
            "2026-02-04 16:54:05.428456: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.6 = (f32[32,32,26,26]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,1,28,28]{3,2,1,0} %bitcast.499, f32[32,1,3,3]{3,2,1,0} %bitcast.506, f32[32]{0} %bitcast.508), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2026-02-04 16:54:05.443243: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[32,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[32,32,13,13]{3,2,1,0} %bitcast.515, f32[64,32,3,3]{3,2,1,0} %bitcast.522, f32[64]{0} %bitcast.524), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "2026-02-04 16:54:06.670912: I external/local_xla/xla/service/gpu/autotuning/conv_algorithm_picker.cc:549] Omitted potentially buggy algorithm eng14{k25=2} for conv %cudnn-conv-bias-activation.7 = (f32[16,64,11,11]{3,2,1,0}, u8[0]{0}) custom-call(f32[16,32,13,13]{3,2,1,0} %bitcast.515, f32[64,32,3,3]{3,2,1,0} %bitcast.522, f32[64]{0} %bitcast.524), window={size=3x3}, dim_labels=bf01_oi01->bf01, custom_call_target=\"__cudnn$convBiasActivationForward\", metadata={op_type=\"Conv2D\" op_name=\"sequential_1/conv2d_1_2/convolution\" source_file=\"/usr/local/lib/python3.12/dist-packages/tensorflow/python/framework/ops.py\" source_line=1200}, backend_config={\"operation_queue_id\":\"0\",\"wait_on_operation_queues\":[],\"cudnn_conv_backend_config\":{\"conv_result_scale\":1,\"activation_mode\":\"kRelu\",\"side_input_scale\":0,\"leakyrelu_alpha\":0},\"force_earliest_schedule\":false}\n",
            "Final Test Accuracy: 98.92%\n",
            "\n",
            "[Success] Results saved to results_cnn.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile transfer_learning.py\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras import layers, models, Input\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# Ensure models directory exists\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "def run_transfer_learning():\n",
        "    print(\"--- 1. Loading FULL CIFAR-10 Data ---\")\n",
        "    (X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "    # Cast to float\n",
        "    X_train = X_train.astype(\"float32\")\n",
        "    X_test = X_test.astype(\"float32\")\n",
        "\n",
        "    print(f\"Training on {len(X_train)} images...\")\n",
        "\n",
        "    print(\"--- 2. Building Architecture with Augmentation ---\")\n",
        "\n",
        "    inputs = Input(shape=(32, 32, 3))\n",
        "\n",
        "    # Data Augmentation\n",
        "    x = layers.RandomFlip(\"horizontal\")(inputs)\n",
        "    x = layers.RandomRotation(0.1)(x)\n",
        "\n",
        "    # Resize to 96x96\n",
        "    x = layers.Lambda(lambda img: tf.image.resize(img, (96, 96)))(x)\n",
        "\n",
        "    # Preprocess\n",
        "    x = layers.Lambda(lambda img: tf.keras.applications.mobilenet_v2.preprocess_input(img))(x)\n",
        "\n",
        "    # Base Model\n",
        "    base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=x)\n",
        "    base_model.trainable = False\n",
        "\n",
        "    # Head\n",
        "    x = base_model.output\n",
        "    x = layers.GlobalAveragePooling2D()(x)\n",
        "    x = layers.Dense(128, activation='relu')(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    outputs = layers.Dense(10, activation='softmax')(x)\n",
        "\n",
        "    model = models.Model(inputs=inputs, outputs=outputs)\n",
        "\n",
        "    model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print(\"--- 3. Phase 1: Training Head ---\")\n",
        "    history = model.fit(X_train, y_train, epochs=8, batch_size=64, validation_split=0.2)\n",
        "\n",
        "    print(\"--- 4. Phase 2: Fine-Tuning ---\")\n",
        "    base_model.trainable = True\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    history_fine = model.fit(X_train, y_train, epochs=8, batch_size=64, validation_split=0.2)\n",
        "\n",
        "    # Evaluate\n",
        "    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "    print(f\"Final Test Accuracy: {test_acc*100:.2f}%\")\n",
        "\n",
        "    # --- THIS WAS THE BROKEN LINE ---\n",
        "    model.save(\"models/transfer_learning_mobilenet.keras\")\n",
        "\n",
        "    with open(\"results_transfer.txt\", \"w\") as f:\n",
        "        f.write(f\"Transfer Learning Accuracy: {test_acc*100:.2f}%\")\n",
        "    print(\"\\n[Success] Results saved to results_transfer.txt\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_transfer_learning()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gOeIUjp_lI4d",
        "outputId": "e92361a0-a414-456a-d76e-095c24428093"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting transfer_learning.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python transfer_learning.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2T-HgI6jlOxF",
        "outputId": "e14845ef-a715-4499-adf8-096d7ebc4b8b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2026-02-04 17:17:59.207949: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1770225479.225933   12137 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1770225479.231520   12137 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "W0000 00:00:1770225479.245484   12137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770225479.245508   12137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770225479.245512   12137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "W0000 00:00:1770225479.245517   12137 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
            "2026-02-04 17:17:59.249800: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "--- 1. Loading FULL CIFAR-10 Data ---\n",
            "Training on 50000 images...\n",
            "--- 2. Building Architecture with Augmentation ---\n",
            "2026-02-04 17:18:07.254136: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
            "I0000 00:00:1770225487.254330   12137 gpu_device.cc:2019] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
            "/content/transfer_learning.py:35: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n",
            "  base_model = MobileNetV2(weights='imagenet', include_top=False, input_tensor=x)\n",
            "--- 3. Phase 1: Training Head ---\n",
            "Epoch 1/8\n",
            "I0000 00:00:1770225495.922803   12192 cuda_dnn.cc:529] Loaded cuDNN version 91002\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 29ms/step - accuracy: 0.4944 - loss: 1.4917 - val_accuracy: 0.7458 - val_loss: 0.7494\n",
            "Epoch 2/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.6436 - loss: 1.0195 - val_accuracy: 0.7671 - val_loss: 0.6869\n",
            "Epoch 3/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.6580 - loss: 0.9833 - val_accuracy: 0.7779 - val_loss: 0.6440\n",
            "Epoch 4/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 26ms/step - accuracy: 0.6748 - loss: 0.9338 - val_accuracy: 0.7765 - val_loss: 0.6555\n",
            "Epoch 5/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.6744 - loss: 0.9279 - val_accuracy: 0.7857 - val_loss: 0.6241\n",
            "Epoch 6/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.6838 - loss: 0.9076 - val_accuracy: 0.7955 - val_loss: 0.6006\n",
            "Epoch 7/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 27ms/step - accuracy: 0.6842 - loss: 0.9015 - val_accuracy: 0.7874 - val_loss: 0.6051\n",
            "Epoch 8/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 26ms/step - accuracy: 0.6895 - loss: 0.8881 - val_accuracy: 0.7838 - val_loss: 0.6222\n",
            "--- 4. Phase 2: Fine-Tuning ---\n",
            "Epoch 1/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m99s\u001b[0m 122ms/step - accuracy: 0.5516 - loss: 1.2993 - val_accuracy: 0.6884 - val_loss: 0.9055\n",
            "Epoch 2/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.6747 - loss: 0.9408 - val_accuracy: 0.6852 - val_loss: 0.9213\n",
            "Epoch 3/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7230 - loss: 0.8153 - val_accuracy: 0.7543 - val_loss: 0.7240\n",
            "Epoch 4/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7483 - loss: 0.7426 - val_accuracy: 0.8123 - val_loss: 0.5387\n",
            "Epoch 5/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7692 - loss: 0.6808 - val_accuracy: 0.8474 - val_loss: 0.4537\n",
            "Epoch 6/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7857 - loss: 0.6245 - val_accuracy: 0.8642 - val_loss: 0.4071\n",
            "Epoch 7/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 119ms/step - accuracy: 0.7985 - loss: 0.5851 - val_accuracy: 0.8673 - val_loss: 0.3908\n",
            "Epoch 8/8\n",
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 119ms/step - accuracy: 0.8107 - loss: 0.5607 - val_accuracy: 0.8750 - val_loss: 0.3680\n",
            "Final Test Accuracy: 86.83%\n",
            "\n",
            "[Success] Results saved to results_transfer.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile training_pipeline.py\n",
        "import os\n",
        "\n",
        "def run_pipeline():\n",
        "    print(\"=======================================\")\n",
        "    print(\"   DAY 4: DEEP LEARNING PIPELINE      \")\n",
        "    print(\"=======================================\")\n",
        "\n",
        "    # Step 1\n",
        "    print(\"\\n[Step 1] Running Manual Neural Network...\")\n",
        "    os.system(\"python neural_network_scratch.py\")\n",
        "\n",
        "    # Step 2\n",
        "    print(\"\\n[Step 2] Training CNN on MNIST...\")\n",
        "    os.system(\"python cnn_classifier.py\")\n",
        "\n",
        "    # Step 3\n",
        "    print(\"\\n[Step 3] Applying Transfer Learning...\")\n",
        "    os.system(\"python transfer_learning.py\")\n",
        "\n",
        "    print(\"\\n=======================================\")\n",
        "    print(\"   PIPELINE COMPLETE. CHECK FILES.     \")\n",
        "    print(\"=======================================\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    run_pipeline()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zbobskoEqKr5",
        "outputId": "c9ebb265-af71-4362-e967-2b2eaeb4f4d9"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing training_pipeline.py\n"
          ]
        }
      ]
    }
  ]
}